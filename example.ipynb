{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a example notebook for loading the the GTX dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xjiae/.conda/envs/hddds/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-06-06 21:08:17.626769: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from dataset import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-series datasets \n",
    "Below are the sample codes to access the dataset objects. The files are large, which could take some time to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([86])\n",
      "y is: 0\n",
      "a shape: torch.Size([86])\n"
     ]
    }
   ],
   "source": [
    "hai = HAIDataset(contents=\"train\")\n",
    "x, y, a = hai[0] # x.shape = a.shape = (86,)\n",
    "print(f\"x shape: {x.shape}\")\n",
    "print(f\"y is: {y}\")\n",
    "print(f\"a shape: {a.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of valid windows: 1003808\n",
      "x shape: torch.Size([99, 86])\n",
      "y is: 0\n",
      "a shape: torch.Size([99, 86])\n",
      "l shape: torch.Size([86])\n"
     ]
    }
   ],
   "source": [
    "hai_slide = HAISlidingDataset(window_size=100, \n",
    "                              stride=1, \n",
    "                              contents=\"train\")\n",
    "x, y, a, l = hai_slide[0] # x.shape = a.shape = (99,86), l is the last timestamp in the window\n",
    "print(f\"x shape: {x.shape}\")\n",
    "print(f\"y is: {y}\")\n",
    "print(f\"a shape: {a.shape}\")\n",
    "print(f\"l shape: {l.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([51])\n",
      "y is: 0\n",
      "a shape: torch.Size([51])\n"
     ]
    }
   ],
   "source": [
    "swat = SWaTDataset(contents=\"train\")\n",
    "x, y, a = swat[0] # x.shape = a.shape = (51,)\n",
    "print(f\"x shape: {x.shape}\")\n",
    "print(f\"y is: {y}\")\n",
    "print(f\"a shape: {a.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of valid windows: 496701\n",
      "x shape: torch.Size([99, 51])\n",
      "y is: 0\n",
      "a shape: torch.Size([99, 51])\n",
      "l shape: torch.Size([51])\n"
     ]
    }
   ],
   "source": [
    "swat_slide = SWaTSlidingDataset(window_size=100, \n",
    "                              stride=1, \n",
    "                              contents=\"train\")\n",
    "x, y, a, l = swat_slide[0] # x.shape = a.shape = (99,51), l is the last timestamp in the window\n",
    "print(f\"x shape: {x.shape}\")\n",
    "print(f\"y is: {y}\")\n",
    "print(f\"a shape: {a.shape}\")\n",
    "print(f\"l shape: {l.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([127])\n",
      "y is: 0.0\n",
      "a shape: torch.Size([127])\n"
     ]
    }
   ],
   "source": [
    "wadi = WADIDataset(contents=\"train\")\n",
    "x, y, a = wadi[0] # x.shape = a.shape = (127,)\n",
    "print(f\"x shape: {x.shape}\")\n",
    "print(f\"y is: {y}\")\n",
    "print(f\"a shape: {a.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of valid windows: 1209502\n",
      "x shape: torch.Size([99, 127])\n",
      "y is: 0\n",
      "a shape: torch.Size([99, 127])\n",
      "l shape: torch.Size([127])\n"
     ]
    }
   ],
   "source": [
    "wadi_slide = WADISlidingDataset(window_size=100, \n",
    "                              stride=1, \n",
    "                              contents=\"train\")\n",
    "x, y, a, l = wadi_slide[0] # x.shape = a.shape = (99,127), l is the last timestamp in the window\n",
    "print(f\"x shape: {x.shape}\")\n",
    "print(f\"y is: {y}\")\n",
    "print(f\"a shape: {a.shape}\")\n",
    "print(f\"l shape: {l.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([3, 256, 256])\n",
      "y is: 0\n",
      "a shape: torch.Size([1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "mvtec = MVTecDataset(\"hazelnut\", input_size=256, is_train=True)\n",
    "x, y, a = mvtec[0] # x.shape = (3, 256, 256) a.shape = (1, 256, 256)\n",
    "print(f\"x shape: {x.shape}\")\n",
    "print(f\"y is: {y}\")\n",
    "print(f\"a shape: {a.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading cache from data/squad/cache/train_roberta-base_384.cache\n",
      "x: <s> The difference in the above factors for the case of Î¸=0 is the reason that most broadcasting (transmissions intended for the public) uses vertical polarization. For receivers near the ground, horizontally polarized transmissions suffer cancellation. For best reception the receiving antennas for these signals are likewise vertically polarized. In some applications where the receiving antenna must work in any position, as in mobile phones, the base station antennas use mixed polarization, such as linear polarization at an angle (with both vertical and horizontal components) or circular polarization.\n",
      "y: What is one use that would require an antenna to receive signals in various ways at once?</s></s></s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "a:  mobile phones\n"
     ]
    }
   ],
   "source": [
    "squad = SquadDataset(\"roberta-base\", is_train=True)\n",
    "ret, roberta = squad[0], squad.tokenizer\n",
    "question_mask, context_mask = ret[6].bool(), (1-ret[6]).bool()\n",
    "x = roberta.decode(ret[0][context_mask]) # context\n",
    "y = roberta.decode(ret[0][question_mask]) # question\n",
    "a = roberta.decode(ret[0][ret[3]:ret[4]]) # answer\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y: {y}\")\n",
    "print(f\"a: {a}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the sample use of dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloder for HAI\n",
    "ret = get_hai_dataloaders(normalize = False, train_batch_size = 32,\n",
    "                          valid_batch_size = 32, \n",
    "                          mix_good_and_anom = True,\n",
    "                          train_frac = 0.7, seed = 1234)\n",
    "train_dataloader  = ret[\"train_dataloader\"]\n",
    "valid_dataloader = ret[\"valid_dataloader\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of valid windows: 9935\n",
      "# of valid windows: 8993\n"
     ]
    }
   ],
   "source": [
    "# dataloder for SWaT slinding\n",
    "ret = get_swat_sliding_dataloaders(window_size=100, stride=50,\n",
    "                                   train_batch_size = 32,\n",
    "                                    valid_batch_size = 32, \n",
    "                                    mix_good_and_anom = True,\n",
    "                                    train_frac = 0.7, seed = 1234)\n",
    "train_dataloader  = ret[\"train_dataloader\"]\n",
    "valid_dataloader = ret[\"valid_dataloader\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = get_mvtec_dataloaders(\"all\", \n",
    "                            train_batch_size = 32,\n",
    "                            valid_batch_size = 32, \n",
    "                            mix_good_and_anom = True,\n",
    "                            train_frac = 0.7, seed = 1234)\n",
    "train_dataloader  = ret[\"train_dataloader\"]\n",
    "valid_dataloader = ret[\"valid_dataloader\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading cache from data/squad/cache/train_roberta-base_384.cache\n",
      "loading cache from data/squad/cache/eval_roberta-base_384.cache\n"
     ]
    }
   ],
   "source": [
    "ret = get_squad_dataloaders(tokenizer_or_name = \"roberta-base\", \n",
    "                            train_batch_size = 32,\n",
    "                            valid_batch_size = 32)\n",
    "train_dataloader  = ret[\"train_dataloader\"]\n",
    "valid_dataloader = ret[\"valid_dataloader\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
